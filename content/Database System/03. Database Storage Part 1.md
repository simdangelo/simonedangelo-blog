---
date: 2024-06-01
modified: 2024-09-04T22:05:43+02:00
---
# 0. Resources
* [F2023 \#03 - Database Storage Part 1 (CMU Intro to Database Systems)](https://www.youtube.com/watch?v=DJ5u5HrbcMk&list=PLSE8ODhjZXjbj8BMuIrRcacnQh20hmY9g&index=4)

---

# 1. Course Outline
The way we think about a DataBase Management System is like a bunch of layers and each layer provides different functionalities:

![](Database%20System/attachments/a0cc8a95a609e8388256c8f807c059bc.png)

We start from the bottom one: **Disk Manager**.
# 2. Disk-based Architecture
For the methods we’ll discuss in the course, we’re going to assume that the architecture we’re trying to build is called **Disk-based Database System**, meaning that the DBMS assumes that the primary storage location of the database in on **non-volatile disk** (SSD, Hard Drive, Cloud [S3]). All the things we’re going to build in the DBMS are really designed to coordinate the movement of data back and forth from **Disk** into **Memory** (that is the classical Von-Neumann architecture).

The way to think about what **Storage** looks like is in therm of this hierarchy:

![](Database%20System/attachments/facda4ee861afedd59d260ea7d685020.png)

At the top of the storage hierarchy, you have the devices that are closest to the CPU. This is the fastest storage, but it is also the smallest and most expensive. The further you get away from the CPU, the larger, but slower the storage devices get. These devices also get cheaper per GB.  
From our perspective the only thing we care about is the division between **Volatile** and **Non-Volatile** storage. We assume that data is going to be **persistent**.

**Non Volatile Devices:**
- **Non-persistent**: if you pull the power from the machine, then the data is lost.
- **Random Access** & **Byte-Addressable**: storage supports fast Random Access with byte-addressable locations. This means that the program can jump to any byte address and get the data that is there.
- For our purpose, we will always refer to this storage class as “**Memory**”.

**Volatile Decives**:
- **Persistent**: the storage devices does not require continuous power in order for the device to retain the bits that it is storing.
- **Sequential Access** & **Block-Addressable**: in order to read a value at a particular offset, the program first has to load the 4 KB page into memory that holds the value the program wants to read (Block-Addressable). Non-Volatile storage is traditionally better at Sequential Access (reading multiple contiguous chunks of data at the same time).
- We will refer to this as “**Disk**”. We will not make a (major) distinction between solid-state storage (SSD) and spinning hard drives (HDD).

Since our DBMS architecture assumes that the database is stored on disk, the components of the DBMS are responsible for figuring out how to move data between non-volatile disk and volatile memory since the system cannot operate on the data directly on disk.  
# *. In-Depth Comparison of Byte and Word Addressing:
Source:
* [https://www.youtube.com/watch?v=QOrAFDZABsM&ab_channel=LearningSimplified](https://www.youtube.com/watch?v=QOrAFDZABsM&ab_channel=LearningSimplified)

Generally we can store in form of 0s and 1s. Suppose a memory device that can store either a 0 or 1. If we group eight such devices, they can store 8 **Bits** and we call this group of 8 cells as **Byte**:

→1 byte = 8 bits

In the same way when we group several Bytes, then we call it as **Words**. But there is not fixed value of how many bytes comprise a one word:

→1 words = ? bytes

When you see 32-bit machines and 64-bit machines, these numbers generally denote the size of the Word: 32-bit machine means the size of the word is 32 bits (or 4-bytes):

→32-bit: 1 word = 4 bytes = 32 bits

Let’s draw a memory of size 4096x32:

![](Database%20System/attachments/195d236ff474df999f4eb8ea3dadbc51.png)

Each layer is a word, so we have 4096 words (each identified by an address i from 0 to 4095) and each word is of 32 bits (or 4 bytes).

Let’s draw another memory of size 4096x32 which shows even the bytes as well representing by the green lines:

![](Database%20System/attachments/e79ac662c2ba5f978f09b3976edfeef0.png)

So, while before we had the address of each word (i from 0 to 4095), now we have address of each byte.

Let’s find a relationship between the two memories:
- the address of the first word is the same as the address of the first byte → i=j;
- the address of the second word is the same as the address of the fifth byte → i+1=j+4;
- …

![](Database%20System/attachments/1abbaa2f437213a4f7c35683e96d8319.png)

Notice that to get the next successive location of a word you have to add 4 to the address of the first bytes of the previous word:
- the address of the first word (i) corresponds to the address of the first byte → i = j
- to get the address of the second word (i+1) you have to add 4 to j → i+1 = j+4
- to get the address of the third word (i+2) you have to add 4 to j → i+2 = j+8

The first memory is called **Word-Addressable storage**, meaning that to read the next word we add 1 to the current location.

The second memory is called **Byte-Addressable storage**, meaning that to read the next word location we add the number of bytes that each word comprises to the current location.

How many bytes are required to represent 4096 locations? The binary form of 4096 is 100000000000 (1 with 11 0s) that is equal to 2^12. So we need 12 bits to represent each word address.

But how do we address if we want to address each byte? $4096 \cdot 4 = 2^{12}\cdot 2^2=2^{14}$﻿. So 14 bits are required to represent each byte address.
# Interesting Memory Playlist, youtube channel (to do)

[https://www.youtube.com/playlist?list=PLBlnK6fEyqRjdT1xkkBZSXKwFKqQoYhwy](https://www.youtube.com/playlist?list=PLBlnK6fEyqRjdT1xkkBZSXKwFKqQoYhwy)

# 2. Disk-based Architecture (continuing)
Random access on non-volatile storage is almost always much slower than sequential access. DBMS will want to **maximize sequential access**, so we’ll choose potentially algorithms that maximize sequential access of the data. This is because accessing adjacent blocks is cheaper, so I want to do that as much as possible. Say I want to get 10 MB and there are 1-MB blocks, if those 1-MB blocks are scattered in different location, I need to jump to those different location with random access memory to get that data, or alternatively, if they’re aligned together contiguous, in theory I can so one fetch command to get those 1-MB blocks and that is going to be way more efficient.

Here’s another visualization of the storage hierarchy showing other characteristics:

![](Database%20System/attachments/0176ee0784c18cf01ddba56d4e620189.png)

![](Database%20System/attachments/51415058aeb31fff5166a418bef1a653.png)

**System Design Goals**: Reading/Writing to disk is expensive, so it must be managed carefully to avoid large stalls and performance degradation. We want to give the illusion that we’re operating with the DB entirely in Memory (especially for large DBs with TB or PB of data). This sound like having **Virtual Memory**. The problem is that, as DBMS developers, we want to build our system by not relying on the OS to do anything, but by doing as mush as we can ourselves.

Let’s describe point by point the high-level diagram about what we want to build:
1. Database File: we break our Database file on the Disk into Pages;
2. Buffer Pool: the DBMS allocates this kind of memory and we use it as staging area where we bring pages in from the disk;
3. Engine Execution: it’s going to run our queries and suppose it want page \#2;
4. bring in the page directory that’s going to tell us where the pages are on the disk;
5. then it’ll make a call to the OS and bring that page into memory;
6. the Buffer Pool will give back the Execution Engine a 64-bit pointer in memory of where this page exists;
    ![](Database%20System/attachments/ccc008e5e7cae172f14f4f83324504b3.png)
    
7. it’s up to the Execution Engine to interpret what’s inside that page;
8. let’s say once you do a bunch of updates, it makes changes to page\#2;
9. then the DBMS is responsible for writing this back to Disk to make sure any changes are persistent.
    ![](Database%20System/attachments/83796c62f232c5579cb99fa88afcfa54.png)
    

---
# 3. DBMS vs. OS

*to do. i did not understand well*

---

# 4. Database Storage
* **Problem 1**: How the DBMS represents the database in files on disk (in this lesson).
* **Problem 2**: How the DBMS manages its memory and moves data back-and-forth from disk.

---

# 5. How the DBMS represents the database in files on disk
There are 3 layers of what data is going to look like:
1. **File Storage**: what these files actually look like;
2. **Page Layout**: within a file, there will be **Pages** because we’re going to break it up into different chunks.
3. **Tuple Layout**: within pages, we have **Tuples**.
## 5.1. File Storage
The DBMS stores a database as one file (SQLite, DuckDB) or more files (Postgres, MySQL) on disk typically in proprietary format. The OS doesn’t know anything about the contents of these files; only the DBMS knows how to decipher their contents, since it is encoded in a way specific to the DBMS. We’ll discuss portable file formats (Parquet, Avro, Orc, Arrow) next week.

  
**Storage Manager**
The **Storage Manager** (sometimes called Storage Engine) is responsible for maintaining database’s files. It organizes the files as a **Collection of Pages**. DBMS:
- tracks data read/written to pages;
- tracks the available space.

A DBMS typically does not maintain multiple copies of a page on disk.

**Database Pages**
The DBMS organizes the database across one or more files in fixed-size blocks of data called **Pages**:
- It can contain tuples, meta-data, indexes, log records, etc.
- Most systems do not mix page types, meaning that you don’t take a 1-MB page and put in data coming from different tables, or indexes, or meta-data. For simplicity, we’re going to assume that one page belongs to some objects in the DB (a table, indexes, etc.) and it only contains data for that particular object.
- Some system require page to be self-contained, meaning that all the information, all the meta-data we need to have in order to understand that’s inside that page, has to be included in the page itself (Oracle is the most famous provider to do that). This is because if there is some corruption in the DB files, you don’t want to have some Pages that contains the meta-data about the table get blown away and then you can’t understand what’s in any other page (replication can solve this problem). _Non ho capito bene._
- Each page is given a unique identifier (a page ID) and there’ll be some methods that the DBMS uses to allow to map a page ID to some physical location on the storage device. Ex: consider the page\#3→there are some methods to know how to find that page in the physical location.

There are three different notions of “Pages” in DBMS:
1. **Hardware Page** (lowest level): usually 4KB. This is the size of block of data that the storage device can guarantee that it can do Atomic Write. Put in another way: the storage device guarantees an atomic write of the size of the hardware page. If the hardware page is 4 KB and the system tries to write 4 KB to the disk, either all 4 KB will be written, or none of it will. If the system tries to write 8 KB to the disk, and I send two 4KB blocks down to the hardware, I may write the first 4KB block and then the system crashes and the second 4KB block didn’t make it. This means that **if our database page is larger than our hardware page, the DBMS will have to take extra measures to ensure that the data gets written out safely** since the program can get partway through writing a database page to disk when the system crashes.
2. **OS Page**: the operating system has its own notion of Page. In Linux by default it is 4 KB and this is about mapping something that’s on the hardware to something that’s in virtual memory. In x64 they also support what are called Huge Page, so you can get page of size 2MB and 1GB.
3. **Database Page**: the DB system has its own notion of Page as well. Typically it can be in the range of 512B (like SQLite)-32KB. The page ID is a way to represent at what offset in some file, for a given page size, we can find the data we’re looking for.
    
    ![](Database%20System/attachments/131057d97d61cf3de1f4eae88fbd0996.png)
    
    How page size affect the performance? Larger page size make writes more expensive because, if I have to write only 1KB and I’m using 16KB-size page, I have to write all 16KB. If my workload were entirely read-only, then I would want large page size (on the opposite, for entirely write-only workload, I would prefer small page size).
    
    Thread about page size performance: [https://dba.stackexchange.com/questions/294587/why-is-the-default-page-size-for-databases-so-small](https://dba.stackexchange.com/questions/294587/why-is-the-default-page-size-for-databases-so-small)
    
**Page Storage Architecture**
Now we’ll see how do we actually keep track of the **mapping between the page ID and the physical location**. Basically we want to know where to find a page with a specific ID into the disk.

Different DBMSs manage pages in files on disk in different ways:
- **Heap File Organization**
- **Tree File Organization**
- **Sequential/Sorted File Organization (ISAM)**
- **Hashing File Organization**

There is no one approach better than the other, but we’ll see Heap File Organization. At this point in our discussion we don’t need to know anything about what’s inside out pages (we don’t care about whether it’s indexes, or tuples, etc.); we just need to know for a given page where I have to go to find it.

**Heap File Organization**
**Heap File Organization** is a fundamental method of storing data in databases. A **Heap File** is an unordered collection of pages with tuples that are stored in random order.
- the only API we need in our storage manager to support a heap file is to Create/Get/Write/Delete Page;
- must also support iterating over all pages.

Managing this heap file is really easy to do if your DB is a single file (like in DuckDB or SQLite) because the only thing to do to find a given page is just know what the page number is and then just do a simple multiplication by the page size:

![](Database%20System/attachments/bc0860769278cda681822410c51a4717.png)

Example given by myself: The page size is 4KB and I want Page3. The physical location is at offset $3 \cdot 4 = 12$﻿.

Things get tricky when you have multiple files (which most DBs have):

![](Database%20System/attachments/e94566f18055f7fbed9c5ec17dc802a8.png)

How to solve that problem? A possible implementation of Heap Files is through what is called **Page Directory**. It’s a special page where the DBMS tracks the location of data pages in the database files. You can think of it as a database inside a database: it’s a database keeping track what is in your database.

The Page Directory
- has to be kept in sync with the actual files on disk;
- records additional data like:
    - the number of free slots per page;
    - list of free/empty pages.

Graphically:

![](Database%20System/attachments/2b761e0a73d9e89a7adf9cb57b477360.png)

## 5.2. Page Layout
**Page Header**
Every page contains a **Header** of meta-data about the page’s contents:
- page size;
- checksum (anytime you fetch something from the disk you compute a fast check to make sure that the data isn’t corrupted);
- DBMS version;
- Transaction Visibility (we’ll talk about transaction later on);
- Compression/Encoding Meta-data;
- Schema Information;
- Data Summary / Sketches (i.e. for a given column what’s the Min and the Max value, so if I need this information I don’t need to read all the data, but just the header).

![](Database%20System/attachments/9f6bbe428b7210505bd80151eda376f8.png)

Remember that some systems require pages to be self-contained (e.g., Oracle).

**Page Layout**
For any page storage architecture, within the page itself we need to decide how to organize the data inside of the page (the tuple data). We are still assuming that we are only storing tuples in pages in **row-oriented storage model** (Lecture \#5), meaning that If I have 5 attributes I will have a tuple and I’ll have those 5 attributes contiguously before I see the next tuple.

There are three different approaches to what could actually be in our pages:
1. **Tuple-oriented Storage** (Today), where we’re only storing tuples and the exact values that those tuples have.
2. **Log-structured Storage** (Lecture \#4), where we store deltas of what changes since the last time time tuple was updated.
3. **Index-organized Storage** (Lecture \#4), where we use a tree structure where in the leaf node we store the data itself.

# 6. Tuple-oriented Storage
We’re answering the question: how to store tuple in a page?

**Strawman Idea**: Keep track of the number of tuples in a page and then just append a new tuple to the end. So if I want to store a new tuple, just look at the header and know what is the number of tuples, then multiply that by the size of the tuple and tells me at what offset I want to write the tuple:

![](Database%20System/attachments/c3abbca6bbd4a602a946f0839e7ba679.png)

This approach is a **bad idea**. Problems:
- What happens if we delete a tuple?
    
    ![](Database%20System/attachments/0ddffd7e94a2d0bf32c06bc29b5343f1.png)
    
    If I delete a tuple from the middle (Tuple \#2) and if I’m only looking at the number of tuples I have, this doesn’t tell me where the free space actually is. So, how am I going to know that I can put a new tuple (Tuple \#4) in there?
    
    I could sequentially scan the page and look at every single tuple to figure out where I can go, bit nobody do this.
    
    ![](Database%20System/attachments/eb199756195e11a059382bafbbb65566.png)
    
- What happens if we have a variable-length attribute? We made the assumption that tuples are fixed-length size, but actually they aren’t. So maybe the free space left by Tuple\#2 is not big enough to containt Tuple\#4. I.e. email addresses are not all the same length so I could see how much space the largest email occupies and then use that size to store all the other email addresses, even if many email addresses are not going to use that entire space.

The most common Page Layout approach to solve these problems is called **Slotted Page**. What we’ll discuss is not exactly what every DBMSs do, but it’s the general idea if you’re using row-oriented DBMS that’s using Tuple-oriented Storage**.**

**Slotted Pages**
- The page has an **Header** that keeps track all the metadata we talked before.
- After the Header there is the **Slot Array** where every position inside it is going to point to the tuples’ starting position offsets in the page (the tuples’ size is stored in the slot array as well).
- Tuples (both fixed- and var-length tuples) start at the **bottom of the page**.
- We’re assuming that the entire tuples are stored inside the page.

![](Database%20System/attachments/8b410c7a923ac185a73e6e279115c75e.png)

To add a tuple, the slot array will grow from the beginning to the end, and the data of the tuples will grow from end to the beginning. The page is considered full when the slot array and the tuple data meet:

![](Database%20System/attachments/779d6dd932cecfb0bb538b871f9d4a65.png)

Now let’s come back to the problem we have seen before: What happens if we delete a tuple? How to deal with the fragmentation due do the empty space left by Tuple\#3?

![](Database%20System/attachments/16004aee66a1e641df8448dc6184bf1e.png)

The answer to the previous question is: it depends on the implementation.
- you could just leave the tuples where they were:
    
    ![](Database%20System/attachments/c5dc0de62250cb2b833b22e1afdc199b.png)
    
- you can slide the old tuples over in order to compact them and all you have to do is to update the slot array with the new physical offset of the tuples you moved:
    
    ![](Database%20System/attachments/de4145b94e0ced1d28e5a08e58eaf28c.png)
    

Some systems use the first approach, some others the second one.

The important thing to note is that: because of the Slot Array I can change the starting offset of each tuple and I don’t need to tell to any other part of the system

Now we need a way to identify tuples. The DBMS assigns each logical tuple a **unique record identifier** that represents its **physical location in the database**.
- This unique record identifier is typically a combination of File ID, Page ID, Slot number. So when you need a specific tuple, if you have this record identifier, you look in the page directory to figure out what page has it, then grab that page, then use the Slot number inside the slot array to figure out what offset inside that page has the tuple you’re looking for.
- Most DBMS do not store these record IDs. Those are something that’s synthetized based on File ID, Page ID, Slot number.
- SQLite uses ROWID as the true primary key and stores them as a hidden attribute.
- Applications should **never** rely on these IDs to mean anything because they represent the physical location of tuples, so they could change because physical location can change (if you run compaction or garbage collection [in Postgres it’s called Vacuum] where I can reorganize a page, maybe the Slot number or the Page ID can change, then the physical location changes, then the ID changes).

![](Database%20System/attachments/274ba52ae9e8094db63ddaf8a9610676.png)

**Record IDs in Postgres**
```sql
SELECT r.ctid, r.* from r;
```

![](Database%20System/attachments/6fcd1bbbe8695b3915c06c70afbed3d3.png)

This record ID is a tuple that gives us the page number and the slot number: `(page_number, slot_number)`. The first row of this table is identified by the record ID `(0,1)`, where 0 is the page number and 1 is the slot number.

If we delete a tuple:
```sql
DELETE FROM r WHERE id = 101;
```

and then show again `r`:
![](Database%20System/attachments/efcd0d3d271cf4264f373a80495e3cdd.png)

We can see that Postgres didn’t move things around by letting the data where they actually lives.

Then let’s insert a new tuple:
```sql
INSERT INTO r VALUES (103, "xxx")
```
The result is:

![](Database%20System/attachments/541185f91260b7eb6827cd9e0bffd335.png)

We can see that Postgres didn’t take the `(0,2)` location (page number 0, slot number 2) and it just appended at the end in the slot number 4.

Now let’s run what in Postgres is called Vacuum, a process that Postgres uses to compact every single page and write out new pages:
```sql
VACUUM FULL r;
```

Then let’s see the table again:

![](Database%20System/attachments/cca7318a1cb20bf75303b989f92e12d0.png)

You can note that tuples have been compacted by inserting the last tuple in the free space left by the deleted tuple.

## 5.3. Tuple Layout
A Tuple is essentially a sequence of bytes and it’s the job of the DBMS to interpret those bytes into attribute types and values.